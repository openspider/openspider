#!/usr/bin/env python3
"""
Babel Tower - é€šç”¨æ™ºèƒ½ç†è§£ä¸æ²Ÿé€šç³»ç»Ÿ
åŸºäº BabelSim ç†å¿µï¼šè·¨è¯­è¨€ã€è·¨æ–‡åŒ–ã€è·¨æ™ºèƒ½çš„å·´åˆ«å¡”

æ ¸å¿ƒå“²å­¦ï¼š
- å·´åˆ«å¡”ï¼šäººç±»ç»Ÿä¸€è¯­è¨€çš„è±¡å¾ -> é€šç”¨æ™ºèƒ½ç†è§£æ¡†æ¶
- è°±ç³»æ€ç»´ï¼šä»ASDåˆ°NTçš„è¡Œä¸ºè¿ç»­ä½“
- æ•°å­—å­ªç”Ÿï¼šä¸ªæ€§åŒ–ç†è§£ä¸ç²¾å‡†å¹²é¢„
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any
from enum import Enum
import hashlib
import json
from datetime import datetime
import numpy as np


class IntelligenceType(Enum):
    """æ™ºèƒ½ç±»å‹æšä¸¾ - å·´åˆ«å¡”çš„å¤šå±‚ç»“æ„"""
    LINGUISTIC = "linguistic"        # è¯­è¨€æ™ºèƒ½
    SPATIAL = "spatial"              # ç©ºé—´æ™ºèƒ½
    BEHAVIORAL = "behavioral"        # è¡Œä¸ºæ™ºèƒ½
    SOCIAL = "social"                # ç¤¾äº¤æ™ºèƒ½
    EMOTIONAL = "emotional"          # æƒ…ç»ªæ™ºèƒ½
    CULTURAL = "cultural"            # æ–‡åŒ–æ™ºèƒ½
    COGNITIVE = "cognitive"          # è®¤çŸ¥æ™ºèƒ½
    PHYSICAL = "physical"            # èº«ä½“è¿åŠ¨æ™ºèƒ½


class SpectrumLevel(Enum):
    """è°±ç³»å±‚çº§ - ä»ASDåˆ°NTçš„è¿ç»­ä½“"""
    # ç¥ç»å¤šæ ·æ€§è°±ç³»
    NEURO_DIVERGENT = "neuro_divergent"   # ç¥ç»å‘æ•£ (å¦‚ASD, ADHD)
    NEURO_TYPICAL = "neuro_typical"        # ç¥ç»å…¸å‹ (NT)
    
    # èƒ½åŠ›è°±ç³»
    HIGH_SUPPORT = "high_support"          # é«˜æ”¯æŒéœ€æ±‚
    MEDIUM_SUPPORT = "medium_support"       # ä¸­ç­‰æ”¯æŒéœ€æ±‚
    LOW_SUPPORT = "low_support"            # ä½æ”¯æŒéœ€æ±‚
    INDEPENDENT = "independent"           # ç‹¬ç«‹
    

@dataclass
class BabelCapsule:
    """
    å·´åˆ«å¡”çŸ¥è¯†èƒ¶å›Š - è·¨æ™ºèƒ½ç»Ÿä¸€è¡¨ç¤º
    
    æ ¸å¿ƒç‰¹ç‚¹ï¼š
    - å¤šè¯­è¨€/å¤šæ¨¡æ€å†…å®¹æ”¯æŒ
    - è°±ç³»æ ‡ç­¾ï¼ˆæ”¯æŒéœ€æ±‚ç­‰çº§ï¼‰
    - è·¨æ™ºèƒ½å…³è”
    - ç²¾å‡†å¹²é¢„å…ƒæ•°æ®
    """
    capsule_id: str
    tower_layer: str                      # å·´åˆ«å¡”å±‚çº§
    content: Dict[str, Any]
    intelligence_types: List[str]          # æ¶‰åŠçš„æ™ºèƒ½ç±»å‹
    spectrum_position: Dict[str, float]    # åœ¨å„è°±ç³»ä¸Šçš„ä½ç½® [0-1]
    multilingual_content: Dict[str, str]    # å¤šè¯­è¨€ç‰ˆæœ¬
    cross_domain_links: List[Dict]         # è·¨åŸŸå…³è”
    digital_twin_config: Optional[Dict]     # æ•°å­—å­ªç”Ÿé…ç½®
    intervention_hints: List[Dict]         # å¹²é¢„å»ºè®®
    metadata: Dict = field(default_factory=dict)


class BabelTower(nn.Module):
    """
    å·´åˆ«å¡”æ ¸å¿ƒæ¶æ„
    
    å±‚çº§ç»“æ„ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  L7: å®‡å®™å±‚ (Universal)              â”‚  <- é€šç”¨æ™ºèƒ½
    â”‚  L6: æ–‡æ˜å±‚ (Civilization)           â”‚  <- è·¨æ–‡åŒ–
    â”‚  L5: ç¤¾ä¼šå±‚ (Society)                â”‚  <- ç¤¾äº¤æ²Ÿé€š
    â”‚  L4: ä¸ªä½“å±‚ (Individual)             â”‚  <- ä¸ªæ€§åŒ–
    â”‚  L3: è¡Œä¸ºå±‚ (Behavioral)             â”‚  <- è¡Œä¸ºæ¨¡å¼
    â”‚  L2: æ¨¡æ€å±‚ (Modal)                 â”‚  <- å¤šæ¨¡æ€
    â”‚  L1: æ„Ÿå®˜å±‚ (Sensory)               â”‚  <- åŸå§‹è¾“å…¥
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    
    def __init__(self, 
                 embed_dim: int = 768,
                 num_layers: int = 12,
                 num_heads: int = 12,
                 num_intelligence_types: int = 7,
                 spectrum_dim: int = 64):
        super().__init__()
        
        self.embed_dim = embed_dim
        self.tower_layers = 7
        
        # 1. æ„Ÿå®˜ç¼–ç å™¨ (Sensory Encoder)
        self.sensory_encoder = nn.ModuleDict({
            'visual': nn.Linear(512, embed_dim),
            'auditory': nn.Linear(512, embed_dim),
            'textual': nn.Linear(512, embed_dim),
            'behavioral': nn.Linear(512, embed_dim),
            'physiological': nn.Linear(128, embed_dim)
        })
        
        # 2. æ¨¡æ€èåˆå±‚ (Modal Fusion)
        self.modal_fusion = nn.ModuleList([
            nn.TransformerEncoderLayer(
                d_model=embed_dim,
                nhead=num_heads,
                dim_feedforward=embed_dim * 4
            ) for _ in range(2)
        ])
        
        # 3. è¡Œä¸ºç¼–ç å™¨ (Behavioral Encoder)
        self.behavioral_encoder = nn.Sequential(
            nn.Linear(embed_dim, embed_dim * 2),
            nn.GELU(),
            nn.Linear(embed_dim * 2, embed_dim),
            nn.LayerNorm(embed_dim)
        )
        
        # 4. è°±ç³»æ„ŸçŸ¥å±‚ (Spectrum-Aware Layer)
        self.spectrum_encoder = nn.ModuleDict({
            'neuro_divergence': nn.Linear(embed_dim, spectrum_dim),
            'support_needs': nn.Linear(embed_dim, spectrum_dim),
            'communication_style': nn.Linear(embed_dim, spectrum_dim),
            'sensory_profile': nn.Linear(embed_dim, spectrum_dim)
        })
        
        # 5. ä¸ªæ€§åŒ–å±‚ (Individualization Layer)
        self.individual_encoder = nn.ModuleDict({
            'preferences': nn.Linear(embed_dim, embed_dim),
            'strengths': nn.Linear(embed_dim, embed_dim),
            'challenges': nn.Linear(embed_dim, embed_dim),
            'goals': nn.Linear(embed_dim, embed_dim)
        })
        
        # 6. ç¤¾äº¤æ²Ÿé€šå±‚ (Social Communication Layer)
        self.social_encoder = nn.ModuleList([
            nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)
            for _ in range(2)
        ])
        
        # 7. æ–‡åŒ–ç†è§£å±‚ (Cultural Understanding Layer)
        self.cultural_encoder = nn.ModuleDict({
            'values': nn.Linear(embed_dim, embed_dim // 2),
            'norms': nn.Linear(embed_dim, embed_dim // 2),
            'practices': nn.Linear(embed_dim, embed_dim // 2),
            'artifacts': nn.Linear(embed_dim, embed_dim // 2)
        })
        
        # 8. æ–‡æ˜ç»¼åˆå±‚ (Civilization Synthesis)
        self.civilization_encoder = nn.Sequential(
            nn.Linear(embed_dim * 4, embed_dim * 2),
            nn.GELU(),
            nn.Linear(embed_dim * 2, embed_dim),
            nn.LayerNorm(embed_dim)
        )
        
        # 9. é€šç”¨æ™ºèƒ½å±‚ (Universal Intelligence)
        self.universal_encoder = nn.Sequential(
            nn.Linear(embed_dim, embed_dim * 2),
            nn.GELU(),
            nn.Linear(embed_dim * 2, embed_dim),
            nn.LayerNorm(embed_dim),
            nn.Linear(embed_dim, num_intelligence_types * 64)
        )
        
        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Linear(num_intelligence_types * 64, embed_dim)
    
    def forward(self, 
                sensory_inputs: Dict[str, torch.Tensor],
                spectrum_context: Optional[Dict[str, torch.Tensor]] = None,
                individual_context: Optional[Dict[str, torch.Tensor]] = None) -> Dict[str, torch.Tensor]:
        """
        å·´åˆ«å¡”å‰å‘ä¼ æ’­
        
        Args:
            sensory_inputs: å¤šæ„Ÿå®˜è¾“å…¥ {'visual': [B, D], 'auditory': [B, D], ...}
            spectrum_context: è°±ç³»ä¸Šä¸‹æ–‡ï¼ˆæ”¯æŒéœ€æ±‚ç­‰ï¼‰
            individual_context: ä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡
            
        Returns:
            outputs: å„å±‚çº§çš„è¡¨ç¤º
        """
        outputs = {}
        
        # L1: æ„Ÿå®˜ç¼–ç 
        sensory_features = []
        for modality, encoder in self.sensory_encoder.items():
            if modality in sensory_inputs:
                feat = encoder(sensory_inputs[modality])
                sensory_features.append(feat)
        
        # æ‹¼æ¥æ‰€æœ‰æ„Ÿå®˜ç‰¹å¾
        x = torch.cat(sensory_features, dim=-1) if len(sensory_features) > 1 else sensory_features[0]
        outputs['sensory'] = x
        
        # L2-L3: æ¨¡æ€èåˆ + è¡Œä¸ºç¼–ç 
        for i, layer in enumerate(self.modal_fusion):
            x = layer(x)
        outputs['modal'] = x
        
        x = self.behavioral_encoder(x)
        outputs['behavioral'] = x
        
        # L4: è°±ç³»æ„ŸçŸ¥
        if spectrum_context:
            spectrum_features = []
            for key, encoder in self.spectrum_encoder.items():
                if key in spectrum_context:
                    feat = encoder(spectrum_context[key])
                    spectrum_features.append(feat)
            x = torch.cat([x] + spectrum_features, dim=-1)
        outputs['spectrum'] = x
        
        # L5: ä¸ªæ€§åŒ–
        if individual_context:
            individual_features = []
            for key, encoder in self.individual_encoder.items():
                if key in individual_context:
                    feat = encoder(individual_context[key])
                    individual_features.append(feat)
            x = torch.cat([x] + individual_features, dim=-1)
        outputs['individual'] = x
        
        # L6: ç¤¾äº¤æ²Ÿé€š
        social_x = x.unsqueeze(1).expand(-1, x.size(1), -1)
        for attn in self.social_encoder:
            attn_out, _ = attn(social_x, social_x, social_x)
            social_x = social_x + attn_out
        outputs['social'] = social_x[:, 0, :]  # CLS token
        
        # L7: æ–‡åŒ–ç†è§£
        cultural_features = []
        for key, encoder in self.cultural_encoder.items():
            feat = encoder(outputs['social'])
            cultural_features.append(feat)
        x = torch.cat(cultural_features, dim=-1)
        outputs['cultural'] = self.civilization_encoder(
            torch.cat([outputs['social'], outputs['behavioral']], dim=-1)
        )
        
        # L8: é€šç”¨æ™ºèƒ½
        universal_out = self.universal_encoder(outputs['cultural'])
        outputs['universal'] = universal_out
        
        return outputs


class BabelSimulator:
    """
    å·´åˆ«æ¨¡æ‹Ÿå™¨ - æ•°å­—å­ªç”Ÿå¼•æ“
    
    åŠŸèƒ½ï¼š
    1. åˆ›å»ºä¸ªä½“/ç¾¤ä½“çš„è¡Œä¸ºæ•°å­—å­ªç”Ÿ
    2. æ¨¡æ‹Ÿä¸åŒæƒ…å¢ƒä¸‹çš„è¡Œä¸ºååº”
    3. é¢„æµ‹å¹²é¢„æ•ˆæœ
    """
    
    def __init__(self, tower_model: BabelTower):
        self.tower = tower_model
        self.twins: Dict[str, Dict] = {}  # æ•°å­—å­ªç”Ÿåº“
        
    def create_twin(self, 
                   twin_id: str,
                   sensory_profile: Dict[str, float],
                   spectrum_position: Dict[str, float],
                   preferences: List[str],
                   challenges: List[str],
                   goals: List[str]) -> Dict:
        """
        åˆ›å»ºä¸ªä½“æ•°å­—å­ªç”Ÿ
        
        Args:
            twin_id: å”¯ä¸€æ ‡è¯†
            sensory_profile: æ„Ÿè§‰æ•æ„Ÿåº¦ {'auditory': 0.8, 'visual': 0.3, ...}
            spectrum_position: è°±ç³»ä½ç½® {'neuro_divergence': 0.7, 'support_needs': 0.5}
            preferences: åå¥½åˆ—è¡¨
            challenges: æŒ‘æˆ˜/å›°éš¾åˆ—è¡¨
            goals: ç›®æ ‡åˆ—è¡¨
        """
        twin = {
            'twin_id': twin_id,
            'sensory_profile': sensory_profile,
            'spectrum_position': spectrum_position,
            'preferences': preferences,
            'challenges': challenges,
            'goals': goals,
            'created_at': datetime.now().isoformat(),
            'interaction_history': [],
            'model_params': {}
        }
        
        # ç¼–ç åˆ°æ¨¡å‹å‚æ•°ç©ºé—´
        self.twins[twin_id] = twin
        return twin
    
    def simulate_response(self,
                         twin_id: str,
                         scenario: Dict[str, Any]) -> Dict:
        """
        æ¨¡æ‹Ÿä¸ªä½“åœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„ååº”
        
        Args:
            twin_id: æ•°å­—å­ªç”ŸID
            scenario: åœºæ™¯æè¿° {'type': 'social', 'context': {...}}
        """
        if twin_id not in self.twins:
            raise ValueError(f"Twin {twin_id} not found")
        
        twin = self.twins[twin_id]
        
        # æ„å»ºè°±ç³»ä¸Šä¸‹æ–‡
        spectrum_context = {
            'neuro_divergence': torch.tensor([[twin['spectrum_position'].get('neuro_divergence', 0.5)]]),
            'support_needs': torch.tensor([[twin['spectrum_position'].get('support_needs', 0.5)]]),
            'communication_style': torch.tensor([[0.5]]),
            'sensory_profile': torch.tensor([[twin['sensory_profile'].get('auditory', 0.5)]])
        }
        
        # æ„å»ºä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡
        individual_context = {
            'preferences': torch.tensor([[0.7]] * len(twin['preferences'])),
            'strengths': torch.tensor([[0.6]] * 3),
            'challenges': torch.tensor([[0.5]] * len(twin['challenges'])),
            'goals': torch.tensor([[0.8]] * len(twin['goals']))
        }
        
        # æ¨¡æ‹Ÿ
        with torch.no_grad():
            outputs = self.tower({}, spectrum_context, individual_context)
        
        response = {
            'scenario': scenario,
            'behavioral_prediction': outputs['behavioral'].numpy().tolist(),
            'social_prediction': outputs['social'].numpy().tolist(),
            'cultural_alignment': outputs['cultural'].numpy().tolist(),
            'suggested_intervention': self._generate_intervention(twin, scenario),
            'confidence_score': np.random.uniform(0.7, 0.95)  # æ¨¡æ‹Ÿç½®ä¿¡åº¦
        }
        
        # è®°å½•äº¤äº’
        twin['interaction_history'].append(response)
        
        return response
    
    def _generate_intervention(self, 
                              twin: Dict, 
                              scenario: Dict) -> List[Dict]:
        """ç”Ÿæˆä¸ªæ€§åŒ–å¹²é¢„å»ºè®®"""
        interventions = []
        
        # åŸºäºæŒ‘æˆ˜ç”Ÿæˆå»ºè®®
        for challenge in twin.get('challenges', []):
            intervention = {
                'challenge': challenge,
                'strategy': f"é’ˆå¯¹{challenge}çš„ä¸ªæ€§åŒ–ç­–ç•¥",
                'approach': [
                    f"è°ƒæ•´ç¯å¢ƒä»¥å‡å°‘{challenge}çš„å½±å“",
                    f"æä¾›æ›¿ä»£æ€§æ²Ÿé€šæ–¹å¼",
                    f"æ¸è¿›å¼æš´éœ²è®­ç»ƒ"
                ],
                'expected_outcome': "è¡Œä¸ºæ”¹å–„"
            }
            interventions.append(intervention)
        
        return interventions


class BabelTranslator:
    """
    å·´åˆ«ç¿»è¯‘å™¨ - è·¨æ™ºèƒ½æ²Ÿé€šæ¡¥æ¢
    
    å®ç°ï¼š
    1. æ™ºèƒ½ç±»å‹è½¬æ¢
    2. è°±ç³»é€‚é…
    3. æ–‡åŒ–æ•æ„Ÿç¿»è¯‘
    """
    
    def __init__(self):
        self.intelligence_mapping = {
            'linguistic': ['verbal', 'written', 'sign', 'symbol'],
            'visual': ['spatial', 'diagram', 'icon', 'color'],
            'behavioral': ['action', 'gesture', 'routine', 'script'],
            'social': ['contextual', 'pragmatic', 'empathetic', 'normative'],
            'emotional': ['affective', 'expressive', 'receptive', 'regulatory'],
            'cultural': ['contextual', 'traditional', 'values_based', 'practice_oriented']
        }
        
        self.spectrum_adapters = {
            'high_support': {
                'simplification': 0.8,
                'visual_support': 0.9,
                'consistency': 0.9,
                'repetition': 0.8
            },
            'medium_support': {
                'simplification': 0.5,
                'visual_support': 0.6,
                'consistency': 0.7,
                'repetition': 0.5
            },
            'low_support': {
                'simplification': 0.2,
                'visual_support': 0.3,
                'consistency': 0.5,
                'repetition': 0.2
            },
            'independent': {
                'simplification': 0.0,
                'visual_support': 0.1,
                'consistency': 0.3,
                'repetition': 0.0
            }
        }
    
    def translate(self,
                 content: Dict[str, Any],
                 source_intelligence: str,
                 target_intelligences: List[str],
                 target_spectrum_level: str = 'neuro_typical') -> Dict[str, str]:
        """
        å°†å†…å®¹ç¿»è¯‘åˆ°å¤šç§æ™ºèƒ½è¡¨è¾¾å½¢å¼
        
        Args:
            content: åŸå§‹å†…å®¹
            source_intelligence: æºæ™ºèƒ½ç±»å‹
            target_intelligences: ç›®æ ‡æ™ºèƒ½ç±»å‹åˆ—è¡¨
            target_spectrum_level: ç›®æ ‡è°±ç³»é€‚é…çº§åˆ«
        """
        translations = {}
        
        # è·å–è°±ç³»é€‚é…å‚æ•°
        adapter = self.spectrum_adapters.get(
            target_spectrum_level, 
            self.spectrum_adapters['neuro_typical']
        )
        
        for target_type in target_intelligences:
            if target_type == source_intelligence:
                translations[target_type] = content
            else:
                # ç”Ÿæˆè½¬æ¢åçš„å†…å®¹
                translated = self._convert_intelligence(
                    content, source_intelligence, target_type, adapter
                )
                translations[target_type] = translated
        
        return {
            'original': content,
            'translations': translations,
            'adapter_used': adapter,
            'spectrum_level': target_spectrum_level
        }
    
    def _convert_intelligence(self, 
                             content: Any, 
                             source: str, 
                             target: str,
                             adapter: Dict) -> Any:
        """æ™ºèƒ½ç±»å‹è½¬æ¢"""
        # ç®€åŒ–çš„è½¬æ¢é€»è¾‘
        if source == 'linguistic' and target == 'visual':
            # æ–‡å­— -> è§†è§‰è¾…åŠ©
            return {
                'type': 'visual',
                'adaptation_level': adapter['visual_support'],
                'content': f"[è§†è§‰åŒ–: {content}]",
                'supports': ['å›¾ç‰‡', 'å›¾è¡¨', 'é¢œè‰²ç¼–ç ']
            }
        elif source == 'linguistic' and target == 'behavioral':
            # æ–‡å­— -> è¡Œä¸ºæ”¯æŒ
            return {
                'type': 'behavioral',
                'adaptation_level': adapter['simplification'],
                'content': f"[è¡Œä¸ºåŒ–: {content}]",
                'supports': ['è„šæœ¬', 'ä¾‹ç¨‹', 'æ­¥éª¤']
            }
        else:
            return {
                'type': target,
                'adaptation_level': adapter['simplification'],
                'content': f"[{target}: {content}]"
            }


class BabelSystem:
    """
    å·´åˆ«å¡”å®Œæ•´ç³»ç»Ÿ
    
    æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œå®ç°ï¼š
    1. çŸ¥è¯†ç†è§£ä¸è¡¨ç¤º
    2. æ•°å­—å­ªç”Ÿä¸æ¨¡æ‹Ÿ
    3. è·¨æ™ºèƒ½ç¿»è¯‘
    4. ç²¾å‡†å¹²é¢„
    """
    
    def __init__(self):
        # æ ¸å¿ƒæ¨¡å‹
        self.tower = BabelTower(
            embed_dim=768,
            num_layers=12,
            num_heads=12,
            num_intelligence_types=7,
            spectrum_dim=64
        )
        
        # æ¨¡æ‹Ÿå™¨
        self.simulator = BabelSimulator(self.tower)
        
        # ç¿»è¯‘å™¨
        self.translator = BabelTranslator()
        
        # çŸ¥è¯†èƒ¶å›Šåº“
        self.knowledge_capsules: Dict[str, BabelCapsule] = {}
        
        # æ•°å­—å­ªç”Ÿåº“
        self.twins: Dict[str, Dict] = {}
    
    def add_knowledge(self,
                     content: str,
                     tower_layer: str,
                     intelligence_types: List[str],
                     spectrum_position: Dict[str, float],
                     source: str = "unknown") -> BabelCapsule:
        """æ·»åŠ çŸ¥è¯†èƒ¶å›Š"""
        capsule_id = f"BC-{datetime.now().strftime('%Y%m%d')}-{hashlib.md5(content.encode()).hexdigest()[:8]}"
        
        capsule = BabelCapsule(
            capsule_id=capsule_id,
            tower_layer=tower_layer,
            content={"text": content},
            intelligence_types=intelligence_types,
            spectrum_position=spectrum_position,
            multilingual_content={},
            cross_domain_links=[],
            digital_twin_config=None,
            intervention_hints=[],
            metadata={"source": source, "created_at": datetime.now().isoformat()}
        )
        
        self.knowledge_capsules[capsule_id] = capsule
        return capsule
    
    def create_individual_twin(self,
                              individual_id: str,
                              profile: Dict) -> Dict:
        """åˆ›å»ºä¸ªä½“æ•°å­—å­ªç”Ÿ"""
        return self.simulator.create_twin(
            twin_id=individual_id,
            sensory_profile=profile.get('sensory', {'auditory': 0.5, 'visual': 0.5}),
            spectrum_position=profile.get('spectrum', {'neuro_divergence': 0.5, 'support_needs': 0.5}),
            preferences=profile.get('preferences', []),
            challenges=profile.get('challenges', []),
            goals=profile.get('goals', [])
        )
    
    def simulate_individual(self,
                           individual_id: str,
                           scenario: Dict) -> Dict:
        """æ¨¡æ‹Ÿä¸ªä½“ååº”"""
        return self.simulator.simulate_response(individual_id, scenario)
    
    def translate_content(self,
                         content: Dict[str, Any],
                         source_intelligence: str,
                         target_intelligences: List[str],
                         spectrum_level: str = 'neuro_typical') -> Dict:
        """ç¿»è¯‘å†…å®¹"""
        return self.translator.translate(
            content, source_intelligence, target_intelligences, spectrum_level
        )


def demo():
    """æ¼”ç¤ºå·´åˆ«å¡”ç³»ç»Ÿ"""
    print("=" * 70)
    print("ğŸ›ï¸  Babel Tower - å·´åˆ«å¡”æ™ºèƒ½ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 70)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = BabelSystem()
    
    # 1. æ·»åŠ çŸ¥è¯†èƒ¶å›Š
    print("\nğŸ“š [1] æ·»åŠ çŸ¥è¯†èƒ¶å›Š...")
    
    # æ–‡åŒ–é—äº§çŸ¥è¯†
    capsule1 = system.add_knowledge(
        content="Hide-JEPAæå‡ºåˆ†å±‚æ„ŸçŸ¥çº¦æŸï¼Œç”¨äºæ–‡åŒ–é—å€çš„è§†è§‰è¡¨ç¤ºå­¦ä¹ ",
        tower_layer="cultural",
        intelligence_types=["visual", "cultural", "cognitive"],
        spectrum_position={"neuro_divergence": 0.1, "support_needs": 0.2},
        source="ICML 2026"
    )
    print(f"   åˆ›å»ºèƒ¶å›Š: {capsule1.capsule_id}")
    print(f"   å±‚çº§: {capsule1.tower_layer}")
    print(f"   æ™ºèƒ½ç±»å‹: {capsule1.intelligence_types}")
    
    # åŒ»ç–—å¹²é¢„çŸ¥è¯†
    capsule2 = system.add_knowledge(
        content="ASDç²¾å‡†å¹²é¢„éœ€è¦ä¸ªæ€§åŒ–æ²Ÿé€šç­–ç•¥å’Œè¡Œä¸ºæ”¯æŒ",
        tower_layer="individual",
        intelligence_types=["behavioral", "social", "emotional"],
        spectrum_position={"neuro_divergence": 0.8, "support_needs": 0.7},
        source="Clinical Research"
    )
    print(f"   åˆ›å»ºèƒ¶å›Š: {capsule2.capsule_id}")
    
    # 2. åˆ›å»ºä¸ªä½“æ•°å­—å­ªç”Ÿ
    print("\nğŸ‘¤ [2] åˆ›å»ºä¸ªä½“æ•°å­—å­ªç”Ÿ...")
    
    autism_profile = {
        'sensory': {'auditory': 0.8, 'visual': 0.3, 'tactile': 0.6},
        'spectrum': {'neuro_divergence': 0.85, 'support_needs': 0.7},
        'preferences': ['ç»“æ„åŒ–æ—¥ç¨‹', 'å•ç‹¬å·¥ä½œ', 'è§†è§‰æ”¯æŒ'],
        'challenges': ['ç¤¾äº¤æ²Ÿé€š', 'æ„Ÿè§‰æ•æ„Ÿ', 'å˜åŒ–é€‚åº”'],
        'goals': ['æé«˜ç¤¾äº¤æŠ€èƒ½', 'ç®¡ç†æ„Ÿè§‰æ•æ„Ÿ', 'å‘å±•ç‹¬ç«‹èƒ½åŠ›']
    }
    
    twin = system.create_individual_twin("user_001", autism_profile)
    print(f"   åˆ›å»ºå­ªç”Ÿ: {twin['twin_id']}")
    print(f"   æ„Ÿè§‰æ•æ„Ÿ: {twin['sensory_profile']}")
    
    # 3. æ¨¡æ‹Ÿåœºæ™¯ååº”
    print("\nğŸ­ [3] æ¨¡æ‹Ÿåœºæ™¯ååº”...")
    
    scenarios = [
        {"type": "social", "context": "å°ç»„è®¨è®º", "difficulty": "medium"},
        {"type": "sensory", "context": "å˜ˆæ‚ç¯å¢ƒ", "difficulty": "high"},
        {"type": "communication", "context": "æ–°æ•™ç»ƒæŒ‡å¯¼", "difficulty": "medium"}
    ]
    
    for scenario in scenarios:
        response = system.simulate_individual("user_001", scenario)
        print(f"\n   åœºæ™¯: {scenario['context']}")
        print(f"   å¹²é¢„å»ºè®®æ•°: {len(response['suggested_intervention'])}")
    
    # 4. å†…å®¹ç¿»è¯‘
    print("\nğŸŒ [4] è·¨æ™ºèƒ½ç¿»è¯‘...")
    
    content = {"text": "è¯·ç†è§£è¿™ä¸ªå¤æ‚çš„æ¦‚å¿µ"}
    translations = system.translate_content(
        content=content,
        source_intelligence="linguistic",
        target_intelligences=["visual", "behavioral"],
        spectrum_level="high_support"
    )
    
    print(f"   åŸæ–‡: {content['text']}")
    for int_type, trans in translations['translations'].items():
        print(f"   â†’ {int_type}: {trans}")
    
    # 5. è¯­ä¹‰ç¢°æ’
    print("\nğŸ’¥ [5] è¯­ä¹‰ç¢°æ’åˆ†æ...")
    
    collision = {
        "capsule_1": capsule1.capsule_id,
        "capsule_2": capsule2.capsule_id,
        "domain_bridge": "æ–‡åŒ–æ™ºèƒ½ â†” è¡Œä¸ºæ™ºèƒ½",
        "potential": "é«˜",
        "direction": "å°†æ–‡åŒ–ç†è§£æ–¹æ³•è¿ç§»åˆ°è¡Œä¸ºå»ºæ¨¡"
    }
    print(f"   ç¢°æ’å¯¹: {collision['capsule_1']} â†” {collision['capsule_2']}")
    print(f"   åŸŸæ¡¥æ¥: {collision['domain_bridge']}")
    print(f"   æ½œåŠ›: {collision['potential']}")
    
    print("\n" + "=" * 70)
    print("âœ… Babel Tower ç³»ç»Ÿæ¼”ç¤ºå®Œæˆ")
    print("=" * 70)
    
    return system


if __name__ == "__main__":
    system = demo()
    
    # ä¿å­˜æ¼”ç¤ºæŠ¥å‘Š
    report = {
        "system": "Babel Tower",
        "version": "1.0",
        "core_modules": ["Tower", "Simulator", "Translator"],
        "capsules_created": 2,
        "twins_created": 1
    }
    
    with open("/root/.openclaw/workspace/hide_jepa_system/babel_demo_report.json", 'w') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print("\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: babel_demo_report.json")
